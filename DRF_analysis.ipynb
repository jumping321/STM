{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Ignore FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Define global variables and paths\n",
    "specific_path = ['L3', 'Mi9', ['T4a', 'T4b', 'T4c', 'T4d'], 'Mi1', 'L1']\n",
    "classification_file_path = './data/classification.txt'\n",
    "connections_file_path = './data/connections.txt'\n",
    "swc_base_path = './data/sk_lod1_783_healed'\n",
    "output_dir = './results/L3_to_T4_to_L1/'\n",
    "\n",
    "# Create output directory if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Read the data\n",
    "classification = pd.read_csv(classification_file_path)\n",
    "connections = pd.read_csv(connections_file_path)\n",
    "\n",
    "# Create a dictionary mapping cell types to their respective root IDs\n",
    "cell_types = ['Mi1', 'Mi9', 'L1', 'L3', 'T4a', 'T4b', 'T4c', 'T4d', 'Tm3']\n",
    "root_ids_by_type = {cell_type: classification[(classification['cell_type'] == cell_type) & (classification['side'] == 'right')]['root_id'].tolist() for cell_type in cell_types}\n",
    "\n",
    "# Get the list of L3 neuron IDs\n",
    "l3_neuron_ids = root_ids_by_type.get('L3', [])\n",
    "\n",
    "# DFS to find paths\n",
    "def find_paths_dfs(neuron_id, connections, root_ids_by_type):\n",
    "    stack = [(neuron_id, [neuron_id], 0)]  # Stack stores (neuron_id, path, current path index)\n",
    "    paths = set()\n",
    "\n",
    "    while stack:\n",
    "        current_neuron, path, current_path_index = stack.pop()\n",
    "\n",
    "        # Check if the path has reached the target (L1)\n",
    "        if current_path_index >= len(specific_path) - 1:\n",
    "            if current_neuron in root_ids_by_type.get('L1', []):\n",
    "                paths.add(tuple(path))  # Add the valid path\n",
    "            continue\n",
    "\n",
    "        # Get the next cell type(s) in the path\n",
    "        next_cell_type = specific_path[current_path_index + 1]\n",
    "        next_cell_type_set = {root_id for cell_type in (next_cell_type if isinstance(next_cell_type, list) else [next_cell_type]) for root_id in root_ids_by_type.get(cell_type, [])}\n",
    "\n",
    "        # Find connections for the next step in the path\n",
    "        possible_connections = connections[(connections['pre_root_id'] == current_neuron) & (connections['post_root_id'].isin(next_cell_type_set))] if current_path_index < 2 else connections[(connections['post_root_id'] == current_neuron) & (connections['pre_root_id'].isin(next_cell_type_set))]\n",
    "\n",
    "        # Traverse the connections and continue building the path\n",
    "        for _, row in possible_connections.iterrows():\n",
    "            next_neuron = row['post_root_id'] if current_path_index < 2 else row['pre_root_id']\n",
    "            if next_neuron != current_neuron:  # Avoid cycles\n",
    "                new_path = path + [next_neuron]\n",
    "                stack.append((next_neuron, new_path, current_path_index + 1))\n",
    "\n",
    "    return [list(path) for path in paths]  # Return all unique paths\n",
    "\n",
    "# Find all paths starting from the given L3 neurons\n",
    "def find_all_paths(start_neuron_ids, connections, root_ids_by_type):\n",
    "    all_paths = {}\n",
    "    for neuron_id in start_neuron_ids:\n",
    "        if neuron_id in connections['pre_root_id'].values:  # Check if the neuron has outgoing connections\n",
    "            paths = find_paths_dfs(neuron_id, connections, root_ids_by_type)\n",
    "            if paths:\n",
    "                all_paths[neuron_id] = paths  # Store the paths for this neuron\n",
    "    return all_paths\n",
    "\n",
    "# Find all paths for L3 neurons and save the result\n",
    "all_paths = find_all_paths(l3_neuron_ids, connections, root_ids_by_type)\n",
    "all_paths_path = os.path.join(output_dir, 'l1_all_paths.pkl')\n",
    "\n",
    "# Save the paths to a pickle file\n",
    "pd.to_pickle(all_paths, all_paths_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Ignore FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Define global variables and paths\n",
    "specific_path = ['L3', 'Tm9', ['T5a', 'T5b', 'T5c', 'T5d'], 'Tm1', 'L2']\n",
    "classification_file_path = './data/classification.txt'\n",
    "connections_file_path = './data/connections.txt'\n",
    "swc_base_path = './data/sk_lod1_783_healed'\n",
    "output_dir = './results/L3_to_T5_to_L2/'\n",
    "\n",
    "# Create output directory if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Read the data\n",
    "classification = pd.read_csv(classification_file_path)\n",
    "connections = pd.read_csv(connections_file_path)\n",
    "\n",
    "# Create a dictionary mapping cell types to their respective root IDs\n",
    "cell_types = ['Tm1', 'Tm9', 'L2', 'L3', 'T5a', 'T5b', 'T5c', 'T5d', 'Tm3']\n",
    "root_ids_by_type = {cell_type: classification[(classification['cell_type'] == cell_type) & (classification['side'] == 'right')]['root_id'].tolist() for cell_type in cell_types}\n",
    "\n",
    "# Get the list of L3 neuron IDs\n",
    "l3_neuron_ids = root_ids_by_type.get('L3', [])\n",
    "\n",
    "# DFS to find paths\n",
    "def find_paths_dfs(neuron_id, connections, root_ids_by_type):\n",
    "    stack = [(neuron_id, [neuron_id], 0)]  # Stack stores (neuron_id, path, current path index)\n",
    "    paths = set()\n",
    "\n",
    "    while stack:\n",
    "        current_neuron, path, current_path_index = stack.pop()\n",
    "\n",
    "        # Check if the path has reached the target (L2)\n",
    "        if current_path_index >= len(specific_path) - 1:\n",
    "            if current_neuron in root_ids_by_type.get('L2', []):\n",
    "                paths.add(tuple(path))  # Add the valid path\n",
    "            continue\n",
    "\n",
    "        # Get the next cell type(s) in the path\n",
    "        next_cell_type = specific_path[current_path_index + 1]\n",
    "        next_cell_type_set = {root_id for cell_type in (next_cell_type if isinstance(next_cell_type, list) else [next_cell_type]) for root_id in root_ids_by_type.get(cell_type, [])}\n",
    "\n",
    "        # Find connections for the next step in the path\n",
    "        possible_connections = connections[(connections['pre_root_id'] == current_neuron) & (connections['post_root_id'].isin(next_cell_type_set))] if current_path_index < 2 else connections[(connections['post_root_id'] == current_neuron) & (connections['pre_root_id'].isin(next_cell_type_set))]\n",
    "\n",
    "        # Traverse the connections and continue building the path\n",
    "        for _, row in possible_connections.iterrows():\n",
    "            next_neuron = row['post_root_id'] if current_path_index < 2 else row['pre_root_id']\n",
    "            if next_neuron != current_neuron:  # Avoid cycles\n",
    "                new_path = path + [next_neuron]\n",
    "                stack.append((next_neuron, new_path, current_path_index + 1))\n",
    "\n",
    "    return [list(path) for path in paths]  # Return all unique paths\n",
    "\n",
    "# Find all paths starting from the given L3 neurons\n",
    "def find_all_paths(start_neuron_ids, connections, root_ids_by_type):\n",
    "    all_paths = {}\n",
    "    for neuron_id in start_neuron_ids:\n",
    "        if neuron_id in connections['pre_root_id'].values:  # Check if the neuron has outgoing connections\n",
    "            paths = find_paths_dfs(neuron_id, connections, root_ids_by_type)\n",
    "            if paths:\n",
    "                all_paths[neuron_id] = paths  # Store the paths for this neuron\n",
    "    return all_paths\n",
    "\n",
    "# Find all paths for L3 neurons and save the result\n",
    "all_paths = find_all_paths(l3_neuron_ids, connections, root_ids_by_type)\n",
    "all_paths_path = os.path.join(output_dir, 'L2_all_paths.pkl')\n",
    "\n",
    "# Save the paths to a pickle file\n",
    "pd.to_pickle(all_paths, all_paths_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Ignore FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Set dataset paths and weight paths\n",
    "classification_file_path = './data/classification.txt'\n",
    "swc_base_path = './data/sk_lod1_783_healed'\n",
    "output_dir = './result/combined_distance_distribution/'\n",
    "\n",
    "# Create the output directory if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Read the classification data\n",
    "classification = pd.read_csv(classification_file_path)\n",
    "\n",
    "# Define cell types and subtypes\n",
    "cell_types = ['L3', 'L2', 'L1']\n",
    "t4_subtypes = ['T4a', 'T4b', 'T4c', 'T4d']\n",
    "t5_subtypes = ['T5a', 'T5b', 'T5c', 'T5d']\n",
    "\n",
    "# Create a dictionary to store root IDs by cell type\n",
    "root_ids_by_type = {cell_type: classification[(classification['cell_type'] == cell_type) & (classification['side'] == 'right')]['root_id'].tolist() for cell_type in cell_types + t4_subtypes + t5_subtypes}\n",
    "\n",
    "# Read column assignment data for Cartesian coordinates\n",
    "column_assignment_file_path = './data/column_assignment.txt'\n",
    "df = pd.read_csv(column_assignment_file_path)\n",
    "\n",
    "# Function to get Cartesian coordinates (x, y) for a given root_id\n",
    "def get_cartesian_by_root_id(root_id):\n",
    "    result = df[df['root_id'] == root_id]\n",
    "    if not result.empty:\n",
    "        p, q = result[['x', 'y']].values[0]\n",
    "        x = 2 * p + 1 if q % 2 == 1 else 2 * p\n",
    "        y = q / 2\n",
    "        return np.array([x, y])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to create hexagonal markers\n",
    "def create_hexagon_marker(size=1, orientation=0):\n",
    "    angles = np.linspace(0, 2 * np.pi, 6, endpoint=False) + np.radians(orientation)\n",
    "    return np.column_stack([np.cos(angles), np.sin(angles)]) * size\n",
    "\n",
    "# Function to calculate directions and distances for each path\n",
    "def calculate_all_directions(paths, root_ids_by_type, subtypes):\n",
    "    directions_by_subtype = {subtype: [] for subtype in subtypes}\n",
    "    for neuron_id, neuron_paths in tqdm(paths.items(), desc=\"Calculating directions\"):\n",
    "        l3_soma = get_cartesian_by_root_id(neuron_id)\n",
    "        if l3_soma is not None:\n",
    "            for path in neuron_paths:\n",
    "                if len(path) > 2:\n",
    "                    t_type_id = path[2]\n",
    "                    for subtype in subtypes:\n",
    "                        if t_type_id in root_ids_by_type[subtype]:\n",
    "                            target_soma = get_cartesian_by_root_id(path[-1])\n",
    "                            if target_soma is not None:\n",
    "                                direction = target_soma - l3_soma\n",
    "                                distance = np.linalg.norm(direction)\n",
    "                                T_soma = get_cartesian_by_root_id(t_type_id)\n",
    "                                if T_soma is not None and distance > 0:\n",
    "                                    directions_by_subtype[subtype].append((T_soma, direction, distance))\n",
    "    return directions_by_subtype\n",
    "\n",
    "# Function to calculate average distances and update the coordinates dictionary\n",
    "def calculate_average_distances(all_xy_coords, distance_sums, distance_counts):\n",
    "    average_distances = {key: distance_sums[key] / distance_counts[key] for key in distance_sums.keys()}\n",
    "    for key, avg_distance in average_distances.items():\n",
    "        all_xy_coords[key] = avg_distance\n",
    "\n",
    "# Function to plot direction maps, adjusting color saturation inversely with distance\n",
    "def plot_directions(directions_by_subtype, ax, title):\n",
    "    all_xy_coords = {tuple(get_cartesian_by_root_id(root_id)): -1 for root_id in df['root_id'].dropna() if get_cartesian_by_root_id(root_id) is not None}\n",
    "    norm = plt.Normalize(-np.pi, np.pi)  # Normalize angles\n",
    "    cmap = plt.cm.hsv  # Use HSV color map\n",
    "    direction_sums, distance_sums, distance_counts = {}, {}, {}\n",
    "\n",
    "    # Sum the directions and distances for each point\n",
    "    for subtype, directions in directions_by_subtype.items():\n",
    "        for T_soma, direction, distance in directions:\n",
    "            key = tuple(T_soma)\n",
    "            if key not in direction_sums:\n",
    "                direction_sums[key] = np.array(direction)\n",
    "                distance_sums[key] = distance\n",
    "                distance_counts[key] = 1\n",
    "            else:\n",
    "                direction_sums[key] += np.array(direction)\n",
    "                distance_sums[key] += distance\n",
    "                distance_counts[key] += 1\n",
    "\n",
    "    # Calculate the average distances\n",
    "    calculate_average_distances(all_xy_coords, distance_sums, distance_counts)\n",
    "\n",
    "    # Find the maximum and minimum distances for normalization\n",
    "    max_distance = max(v for v in all_xy_coords.values() if v >= 0)\n",
    "    min_distance = min(v for v in all_xy_coords.values() if v >= 0)\n",
    "\n",
    "    # Create hexagon marker\n",
    "    hexagon_marker = create_hexagon_marker(size=1, orientation=0)\n",
    "\n",
    "    # Plot the points, coloring them based on the average distance and direction\n",
    "    for (x, y), distance in all_xy_coords.items():\n",
    "        if distance < 0:\n",
    "            ax.scatter(x, y, color='gray', s=45, marker=hexagon_marker, edgecolor='gray')\n",
    "        else:\n",
    "            normalized_distance = (distance - min_distance) / (max_distance - min_distance)\n",
    "            alpha = 1\n",
    "\n",
    "            summed_direction = direction_sums[(x, y)]\n",
    "            angle = np.arctan2(summed_direction[1], summed_direction[0])\n",
    "            color = cmap(norm(angle))\n",
    "            ax.scatter(x, y, color=color, alpha=alpha, s=45, marker=hexagon_marker, edgecolor=color)\n",
    "\n",
    "    # Set plot title and remove axis labels\n",
    "    ax.set_title(title, fontsize=30, fontname='Times New Roman')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "# Function to plot a color wheel with a square boundary\n",
    "def plot_color_wheel(ax):\n",
    "    theta = np.linspace(-np.pi, np.pi, 500)\n",
    "    r = np.linspace(0, 1, 500)\n",
    "    T, R = np.meshgrid(theta, r)\n",
    "    norm = plt.Normalize(-np.pi, np.pi)  # Normalize angles\n",
    "    cmap = plt.cm.hsv  # Use HSV color map\n",
    "    angle_colors = cmap(norm(T))\n",
    "\n",
    "    # Adjust color saturation\n",
    "    for i in range(angle_colors.shape[0]):\n",
    "        angle_colors[i, :, :-1] = angle_colors[i, :, :-1] * R[i, :, None] + (1 - R[i, :, None])\n",
    "\n",
    "    ax.pcolormesh(T, R, angle_colors, shading='auto')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "# Read the T4 and T5 path data\n",
    "t4_paths_path = './result/L3_to_T4_to_L1/l1_all_paths.pkl'\n",
    "t5_paths_path = './result/L3_to_T5_to_L2/l2_all_paths.pkl'\n",
    "t4_paths = pd.read_pickle(t4_paths_path)\n",
    "t5_paths = pd.read_pickle(t5_paths_path)\n",
    "\n",
    "# Calculate directions and distances for T4 and T5 paths\n",
    "l3_to_l1_dirs_and_dists_t4 = calculate_all_directions(t4_paths, root_ids_by_type, t4_subtypes)\n",
    "l3_to_l2_dirs_and_dists_t5 = calculate_all_directions(t5_paths, root_ids_by_type, t5_subtypes)\n",
    "\n",
    "# Create a 4x9 layout, with the last column for the color wheel\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "gs = gridspec.GridSpec(4, 9, figure=fig, wspace=0.1, hspace=0.1)\n",
    "\n",
    "# Plot direction maps for T4 subtypes\n",
    "for i, subtype in enumerate(t4_subtypes):\n",
    "    ax = fig.add_subplot(gs[0:2, (2 * i):(2 * i + 2)])\n",
    "    plot_directions({subtype: l3_to_l1_dirs_and_dists_t4[subtype]}, ax, f\"{subtype}\")\n",
    "\n",
    "# Plot direction maps for T5 subtypes\n",
    "for i, subtype in enumerate(t5_subtypes):\n",
    "    ax = fig.add_subplot(gs[2:4, (2 * i):(2 * i + 2)])\n",
    "    plot_directions({subtype: l3_to_l2_dirs_and_dists_t5[subtype]}, ax, f\"{subtype}\")\n",
    "\n",
    "# Plot the color wheel with a square boundary\n",
    "ax_color_wheel = fig.add_subplot(gs[0:4, 8], projection='polar', frame_on=False)\n",
    "plot_color_wheel(ax_color_wheel)\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Define global variables and paths\n",
    "classification_file_path = './data/classification.txt'\n",
    "connections_file_path = './data/connections.txt'\n",
    "synapses_file_path = './data/synapses.txt'\n",
    "output_dir = './result/LC11/L2_to_LC11/'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Read the data from files\n",
    "classification = pd.read_csv(classification_file_path)\n",
    "connections = pd.read_csv(connections_file_path)\n",
    "synapses = pd.read_csv(synapses_file_path)\n",
    "\n",
    "# Get the list of L2 and LC11 neurons on the right side\n",
    "L2_right_ids = classification[(classification['cell_type'] == 'L2') & (classification['side'] == 'right')]['root_id'].tolist()\n",
    "LC11_right_ids = classification[(classification['hemibrain_type'] == 'LC11') & (classification['side'] == 'right')]['root_id'].tolist()\n",
    "\n",
    "# Allowed cell types for upstream neurons\n",
    "allowed_cell_types = {'Pm', 'LC11', 'T4', 'T5', 'Tm', 'Mi', 'Li', 'L2', 'LPi', 'L3', 'L5', 'DM', 'Y'}\n",
    "\n",
    "# DFS function to find paths and calculate weights\n",
    "def dfs(neuron_id, visited, connections, current_path, all_paths, current_weight):\n",
    "    # If the neuron has been visited or the path is too long, return\n",
    "    if neuron_id in visited or len(current_path) >= 5:\n",
    "        return\n",
    "    visited.add(neuron_id)\n",
    "    current_path.append(neuron_id)\n",
    "\n",
    "    # Get the upstream neurons connected to the current neuron\n",
    "    upstream_neurons = connections[connections['post_root_id'] == neuron_id]\n",
    "\n",
    "    for _, row in upstream_neurons.iterrows():\n",
    "        pre_id = row['pre_root_id']\n",
    "        syn_count = row['syn_count']\n",
    "        nt_type = row['nt_type']\n",
    "\n",
    "        # Get the cell type of the upstream neuron\n",
    "        pre_cell_type = classification.loc[classification['root_id'] == pre_id, 'cell_type']\n",
    "        \n",
    "        if pre_cell_type.empty:\n",
    "            continue\n",
    "        \n",
    "        # Check if the upstream neuronâ€™s type is allowed\n",
    "        pre_cell_type_value = pre_cell_type.values[0]  # Get the first value\n",
    "        \n",
    "        if not isinstance(pre_cell_type_value, str) or not any(allowed in pre_cell_type_value for allowed in allowed_cell_types):\n",
    "            continue  # Skip neurons that don't match the allowed types\n",
    "        \n",
    "        # Filter synapse types and adjust synapse count\n",
    "        if nt_type == 'GABA' or nt_type == 'GLUT':\n",
    "            syn_count = -abs(syn_count)\n",
    "        elif nt_type == 'ACH':\n",
    "            syn_count = abs(syn_count)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # Get the number of output synapses for the upstream neuron\n",
    "        output_synapses = synapses.loc[synapses['root_id'] == pre_id, 'output synapses']\n",
    "        if not output_synapses.empty:\n",
    "            output_synapses = output_synapses.values[0]\n",
    "            weight = float(syn_count) / output_synapses\n",
    "            if abs(weight) < 0.01 and syn_count < 5:\n",
    "                continue  # Skip paths with negligible weight\n",
    "            \n",
    "            # Update the current weight by multiplying with the new weight\n",
    "            new_weight = current_weight * weight\n",
    "            \n",
    "            # Recursively apply DFS for upstream neurons\n",
    "            dfs(pre_id, visited, connections, current_path, all_paths, new_weight)\n",
    "\n",
    "    # If the current neuron is an L2 neuron, save the path and its weight\n",
    "    if neuron_id in L2_right_ids:\n",
    "        all_paths.append((list(current_path), current_weight))\n",
    "    \n",
    "    # Backtrack\n",
    "    current_path.pop()\n",
    "    visited.remove(neuron_id)\n",
    "\n",
    "# Process each LC11 neuron\n",
    "L2_weights = {L2_id: 0 for L2_id in L2_right_ids}  # Initialize L2 weights\n",
    "for LC11_neuron in tqdm(LC11_right_ids, desc=\"Processing LC11 Neurons\"):\n",
    "    visited = set()\n",
    "    current_path = []\n",
    "    all_paths = []\n",
    "    \n",
    "    # Start DFS for the current LC11 neuron with an initial weight of 1\n",
    "    dfs(LC11_neuron, visited, connections, current_path, all_paths, 1)\n",
    "    \n",
    "    # Update the weight for each L2 neuron based on the paths found\n",
    "    for path, weight in all_paths:\n",
    "        L2_neuron_id = path[-1]  # Get the L2 neuron ID from the end of the path\n",
    "        if L2_neuron_id in L2_weights:\n",
    "            L2_weights[L2_neuron_id] += weight  # Add the weight to the L2 neuron\n",
    "\n",
    "    # Write the results to a text file\n",
    "    output_file_path = os.path.join(output_dir, f'{LC11_neuron}.txt')\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for L2_id, total_weight in L2_weights.items():\n",
    "            f.write(f'{L2_id}: {total_weight}\\n')\n",
    "\n",
    "    # Reset L2 weights for the next LC11 neuron\n",
    "    L2_weights = {L2_id: 0 for L2_id in L2_right_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "import math\n",
    "\n",
    "# Suppress FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Replaceable neuron type name\n",
    "neuron_type = 'LC11'  # You can change it to any neuron type, for example, 'LC3'\n",
    "\n",
    "# Define paths dynamically using the neuron type\n",
    "output_dir = f'./result/{neuron_type}/L2_to_{neuron_type}/'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Paths to data files\n",
    "classification_file_path = './data/classification.txt'\n",
    "connections_file_path = './data/connections.txt'\n",
    "synapses_file_path = './data/synapses.txt'\n",
    "column_assignment_file_path = './data/column_assignment.txt'\n",
    "\n",
    "# Load data\n",
    "classification = pd.read_csv(classification_file_path)\n",
    "connections = pd.read_csv(connections_file_path)\n",
    "synapses = pd.read_csv(synapses_file_path)\n",
    "\n",
    "# Get the list of L2 and specific neuron type IDs on the right side\n",
    "L2_right_ids = classification[(classification['cell_type'] == 'L2') & (classification['side'] == 'right')]['root_id'].tolist()\n",
    "LC_right_ids = classification[(classification['hemibrain_type'] == neuron_type) & (classification['side'] == 'right')]['root_id'].tolist()\n",
    "\n",
    "# Load the column assignments\n",
    "df = pd.read_csv(column_assignment_file_path, dtype={'root_id': str})\n",
    "\n",
    "# Function to get the 'x' and 'y' coordinates for a given root_id\n",
    "def get_p_q_by_root_id(root_id):\n",
    "    result = df[df['root_id'] == root_id]\n",
    "    if not result.empty:\n",
    "        return result[['x', 'y']].values[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to convert hexagonal coordinates to Cartesian coordinates\n",
    "def hex_to_cartesian(p, q):\n",
    "    if q % 2 == 1:\n",
    "        x = 2 * p + 1\n",
    "    else:\n",
    "        x = 2 * p\n",
    "    y = q / 2\n",
    "    return x, y\n",
    "\n",
    "# Function to create hexagonal markers for plotting\n",
    "def create_hexagon_marker(size=1, orientation=0):\n",
    "    angles = np.linspace(0, 2 * np.pi, 6, endpoint=False) + np.radians(orientation)\n",
    "    return np.column_stack([np.cos(angles), np.sin(angles)]) * size\n",
    "\n",
    "# Function to determine the grid size dynamically based on the number of neurons\n",
    "def determine_subplot_grid(n):\n",
    "    cols = math.ceil(np.sqrt(n))\n",
    "    rows = math.ceil(n / cols)\n",
    "    return rows, cols\n",
    "\n",
    "# Get the number of neurons for determining the grid size\n",
    "n_neurons = len(LC_right_ids)\n",
    "\n",
    "# Determine the layout of subplots\n",
    "rows, cols = determine_subplot_grid(n_neurons)\n",
    "\n",
    "# Set the size of each subplot\n",
    "figsize_per_subplot = (1.5, 2)  # Size for each subplot\n",
    "fig_width = figsize_per_subplot[0] * cols\n",
    "fig_height = figsize_per_subplot[1] * rows\n",
    "\n",
    "# Create subplots with the calculated size\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(fig_width, fig_height))\n",
    "\n",
    "# Process each neuron and plot its data onto individual subplots\n",
    "for i, LC_neuron in tqdm(enumerate(LC_right_ids), desc=f\"Processing {neuron_type} Neurons\", total=n_neurons):\n",
    "    all_xy_coords = {tuple(hex_to_cartesian(p, q)): 0 for p, q in df[['x', 'y']].dropna().values}\n",
    "    file_path = os.path.join(output_dir, f'{LC_neuron}.txt')\n",
    "    x_coords = []\n",
    "    y_coords = []\n",
    "    nag_coords = []\n",
    "\n",
    "    # Read data from the file and update coordinates with values\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split(': ')\n",
    "                if len(parts) == 2:\n",
    "                    neuron_id = parts[0]\n",
    "                    if neuron_id in df['root_id'].values:\n",
    "                        value = float(parts[1])  # Convert the value to float\n",
    "                        coordinates = get_p_q_by_root_id(neuron_id)\n",
    "                        if coordinates is not None:\n",
    "                            x_cartesian, y_cartesian = hex_to_cartesian(coordinates[0], coordinates[1])  # Convert to Cartesian coordinates\n",
    "                            all_xy_coords[(x_cartesian, y_cartesian)] = value  # Update value\n",
    "                            x_coords.append(x_cartesian)\n",
    "                            y_coords.append(y_cartesian)\n",
    "                            if value < 0:\n",
    "                                nag_coords.append((x_cartesian, y_cartesian))\n",
    "\n",
    "    # Get the current subplot\n",
    "    ax = axs[i // cols, i % cols]\n",
    "\n",
    "    # Set the background color to white for the subplot\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    hexagon_marker = create_hexagon_marker(size=1, orientation=0)  # Create rotated hexagon marker\n",
    "\n",
    "    # Get the maximum positive and negative values, defaulting to 0 if not present\n",
    "    max_positive = max((v for v in all_xy_coords.values() if v > 0), default=0)\n",
    "    max_negative = abs(min((v for v in all_xy_coords.values() if v < 0), default=0))\n",
    "    max_val = max(max_positive, max_negative)\n",
    "\n",
    "    # Define color map from blue to red\n",
    "    cmap = LinearSegmentedColormap.from_list('blue_red', ['blue', 'white', 'red'])\n",
    "\n",
    "    # Normalize the values\n",
    "    norm = Normalize(vmin=-max_val, vmax=max_val)\n",
    "\n",
    "    # Function to determine the color based on value\n",
    "    def get_color(value, max_val):\n",
    "        alpha = max(abs(value) / max_val, 0.1)  # Adjust alpha based on the value, with a minimum of 0.1\n",
    "        if value > 0:\n",
    "            return (1, 0, 0, alpha)  # Red for positive values\n",
    "        elif value < 0:\n",
    "            return (0, 0, 1, alpha)  # Blue for negative values\n",
    "        else:\n",
    "            return (0, 0, 0, 1)  # White for zero values\n",
    "\n",
    "    # Assign colors to each coordinate based on its value\n",
    "    colors = [get_color(all_xy_coords[(x, y)], max_val) for x, y in zip(x_coords, y_coords)]\n",
    "\n",
    "    # Plot the scatter plot for each neuron\n",
    "    if x_coords:  # Only plot if there is data\n",
    "        ax.scatter(x_coords, y_coords, c=colors, s=10, marker=hexagon_marker)\n",
    "    \n",
    "    # Set the title to the neuron ID with the appropriate font and size\n",
    "    ax.set_title(f'{LC_neuron}', fontsize=10, fontname='Times New Roman')\n",
    "    \n",
    "    # Hide axis and grid for clean presentation\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "# Remove extra empty subplots and hide their axes\n",
    "for i in range(len(LC_right_ids), rows * cols):\n",
    "    fig.delaxes(axs.flat[i])  # Remove the extra subplot frames\n",
    "\n",
    "# Set the main title for the entire figure with the specified font and size\n",
    "plt.suptitle(f\"Weights of L2 Neurons Corresponding to Neuron Type: {neuron_type}\", fontsize=20, fontname='Times New Roman')\n",
    "\n",
    "# Adjust the layout of the subplots to fit the figure\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Leave space for the main title\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
